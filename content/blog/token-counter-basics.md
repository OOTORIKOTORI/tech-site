---
title: LLMトークン数とコスト計算入門：プロンプト設計の基礎
description: '課題: トークン数が読めず、予算オーバーやエラーで困る。得られること: トークン概念、モデル別料金、効率的なプロンプト設計の基本。'
date: '2025-11-01'
tags:
  - 'tool:token-counter'
  - 入門
  - ai
  - llm
  - cost
audience: AI開発者・プロンプトエンジニア
type: primer
tool: token-counter
visibility: primer
robots: index
---

「ChatGPT や Claude を使うとコストが予想外に高くなる…」「トークン制限でエラーが出るけど、何トークン使ってるか分からない！」そんな悩みはありませんか？
この記事では、LLM のトークン概念、モデル別の料金体系、効率的なプロンプト設計の基本を短時間で解説します。
まずは関連ツール「LLM Token Counter」で自分のプロンプトを計測してみましょう。

---

## 1. 基本の構造（トークンとは）

**トークン**は LLM が処理する最小単位です。英語では 1 単語が約 1.33 トークン、日本語では 1 文字が約 1 トークンです。

| 言語   | 目安                   | 例                                    |
| ------ | ---------------------- | ------------------------------------- |
| 英語   | 1 単語 ≈ 1.33 トークン | "Hello world" ≈ 2 tokens              |
| 日本語 | 1 文字 ≈ 1 トークン    | "こんにちは世界" ≈ 7 tokens           |
| 混在   | 英単語と日本語を合算   | "Hello 世界" ≈ 1.33 + 2 = 3.33 tokens |

**重要**: モデルごとに最大トークン数（コンテキストウィンドウ）が決まっています。

---

## 2. 主要モデルの料金体系

2025 年時点の主要 LLM モデルの料金（USD / 1M トークン）:

| モデル           | プロバイダ | 入力   | 出力   | 最大トークン |
| ---------------- | ---------- | ------ | ------ | ------------ |
| GPT-4 Turbo      | OpenAI     | $10.00 | $30.00 | 128,000      |
| GPT-3.5 Turbo    | OpenAI     | $0.50  | $1.50  | 16,385       |
| Claude 3 Opus    | Anthropic  | $15.00 | $75.00 | 200,000      |
| Claude 3 Sonnet  | Anthropic  | $3.00  | $15.00 | 200,000      |
| Claude 3 Haiku   | Anthropic  | $0.25  | $1.25  | 200,000      |
| Gemini 1.5 Pro   | Google     | $3.50  | $10.50 | 1,048,576    |
| Gemini 1.5 Flash | Google     | $0.35  | $1.05  | 1,048,576    |

**ポイント**: 出力トークンは入力の 2〜5 倍高いことが多いです。

---

## 3. 実例（コスト計算の手順）

### 例 1: 短いプロンプト（英語）

```
入力: "Explain quantum computing in simple terms" (7 単語 ≈ 9 トークン)
出力: 約 100 トークン（100 単語程度のレスポンス）

GPT-4 Turbo の場合:
- 入力コスト: 9 / 1,000,000 × $10 = $0.00009
- 出力コスト: 100 / 1,000,000 × $30 = $0.003
- 合計: $0.00309 (約 0.5 円)
```

### 例 2: 長いドキュメント要約（日本語）

```
入力: 5,000 文字のレポート ≈ 5,000 トークン
出力: 500 トークンの要約

Claude 3 Sonnet の場合:
- 入力コスト: 5,000 / 1,000,000 × $3 = $0.015
- 出力コスト: 500 / 1,000,000 × $15 = $0.0075
- 合計: $0.0225 (約 3.4 円)
```

---

## 4. 落とし穴（❌ 失敗 →✅ 対策）

### トークン数の見誤り

- ❌ 文字数 = トークン数だと思い込む
- ✅ 英語は 4 文字で約 1 トークン、日本語は 1 文字で約 1 トークン

### 出力コストの見落とし

- ❌ 入力だけ気にして、出力コストを忘れる
- ✅ 出力は入力の 2〜5 倍高い。長い出力を避ける工夫をしましょう

### モデルの最大トークン超過

- ❌ GPT-3.5 Turbo (16k) に 20k トークンを送ってエラー
- ✅ モデルの最大トークン数を確認し、分割送信や要約を検討しましょう

### 不要な繰り返し

- ❌ 同じプロンプトを何度も送信してコスト増
- ✅ キャッシュやバッチ処理を活用しましょう

---

## 5. 手を動かす（3 手で検証）

1. [LLM Token Counter](/tools/token-counter) にアクセスします
2. あなたのプロンプトをテキストエリアに貼り付けます
3. モデルを選択し、出力トークン数を入力してコストを確認します

**試してみよう**:

- 日本語と英語で同じ内容を入力して、トークン数の違いを比較
- 出力トークン数を 100 → 1000 → 10000 と変えてコストの増加を体感

---

## 6. 効率的なプロンプト設計のコツ

### 入力を減らす工夫

1. **要点だけ送る**: 不要な説明や装飾を削る
2. **略語・短縮形**: "Please" → "Pls" などでトークン削減
3. **構造化データ**: JSON や CSV で送ると効率的

### 出力を減らす工夫

1. **箇条書き指定**: "List 3 points" と制限
2. **文字数制限**: "Answer in 50 words or less"
3. **Yes/No 質問**: 長文レスポンスを避ける

### コスト削減のモデル選択

- **簡単なタスク**: GPT-3.5 Turbo や Claude Haiku (安価)
- **複雑な推論**: GPT-4 Turbo や Claude Opus (高性能)
- **大量データ処理**: Gemini Flash (低コスト＋大コンテキスト)

---

## 7. クイズ

1. 英語 100 単語は約何トークンですか？
2. GPT-4 Turbo で 1,000 トークン入力、1,000 トークン出力のコストは？
3. トークン制限エラーを回避する方法を 2 つ挙げてください

### 答え

1. 約 133 トークン（1 単語 ≈ 1.33 トークン）
2. 入力: $0.01、出力: $0.03、合計: $0.04
3. ① プロンプトを分割送信、② より大きいコンテキストウィンドウのモデルを使用

---

## 8. まとめ

- トークンは LLM の処理単位。英語は 1 単語 ≈ 1.33 トークン、日本語は 1 文字 ≈ 1 トークン
- 出力トークンは入力の 2〜5 倍高い。出力を制限する工夫が重要
- モデルごとに最大トークン数と料金が異なる。タスクに応じて選択しましょう
- 不要な繰り返しや冗長な表現を削ってコスト削減
- 「LLM Token Counter」で事前にトークン数とコストを確認しましょう
- 実際に手を動かして、自分のプロンプトを最適化しましょう

---

まずは「LLM Token Counter」で自分のプロンプトを計測してみましょう。
→ [LLM Token Counter & Cost Estimator](/tools/token-counter)
